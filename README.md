# Goal

This codelab is meant to provide reference implementations (and some optimizations advice) for different quantized kernels.

Python is obvious much more easier to read and understand.

This codelab is not intended to cover the quantization schema design or quantization recipes for different kernels.

# Materials
[TensorFlow Lite Model Optimization Toolkit](https://www.tensorflow.org/lite/performance/model_optimization)

[GemmLowp](https://github.com/google/gemmlowp)

[TensorFlow Lite Kernels](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/kernels)

# Credits
The quantization kernel computation methods actually came from benoitjacob@, raziel@, suharshs@ and many other people from the tflite-team.
